{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек для работы с байесовской нейросетью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_probability as tfp\n",
    "# import idx2numpy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "#tf.config.run_functions_eagerly(False)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "num_monte_carlo = 50\n",
    "#from BBLENET5 import BLENET5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bond005/jupyter-notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделение видеопамяти на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "NUM_TRAIN_EXAMPLES = 60000\n",
    "NUM_HELDOUT_EXAMPLES = 10000\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() ## x -картинки, y - метки, (60000,28,28)\n",
    "x_train = x_train.reshape((60000,28,28,1))\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.reshape((10000,28,28,1))\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCallback(Callback):\n",
    "    \n",
    "#     def on_train_batch_begin(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "#     def on_train_batch_end(self, batch, logs=None):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение байесовской нейросети (архитектура LeNet-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) /  tf.cast(30.0 * NUM_TRAIN_EXAMPLES, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tfp.layers.Convolution2DFlipout(6, kernel_size=5, padding='SAME',\n",
    "#                                           kernel_divergence_fn=kl_divergence_function, bias_divergence_fn = kl_divergence_function,\n",
    "#                                           activation='relu',input_shape=(28,28,1)))\n",
    "# #model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2],padding='SAME'))\n",
    "# model.add(tfp.layers.Convolution2DFlipout(16, kernel_size=5, padding='SAME',\n",
    "#                                           kernel_divergence_fn=kl_divergence_function,bias_divergence_fn = kl_divergence_function,\n",
    "#                                           activation='relu'))\n",
    "# #model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2],padding='SAME'))\n",
    "# model.add(tfp.layers.Convolution2DFlipout(120, kernel_size=5, padding='SAME',\n",
    "#                                           kernel_divergence_fn=kl_divergence_function,bias_divergence_fn = kl_divergence_function,\n",
    "#                                           activation='relu'))\n",
    "# #model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tfp.layers.DenseFlipout(84, kernel_divergence_fn=kl_divergence_function,bias_divergence_fn = kl_divergence_function,activation=tf.nn.relu))\n",
    "# model.add(tfp.layers.DenseFlipout(NUM_CLASSES, kernel_divergence_fn=kl_divergence_function,bias_divergence_fn = kl_divergence_function,\n",
    "#                                   activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bond005/env_for_tf22/lib/python3.6/site-packages/tensorflow_probability/python/layers/util.py:106: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tfp.layers.Convolution2DFlipout(6, kernel_size=5, padding='SAME',\n",
    "                                kernel_divergence_fn=kl_divergence_function,\n",
    "                                bias_divergence_fn = kl_divergence_function,\n",
    "                                kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                                    loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                                    untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                                ),\n",
    "                                bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                                    is_singular=True,\n",
    "                                    loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                                    untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                                ),\n",
    "                                activation='relu',input_shape=(28,28,1)),\n",
    "tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2],padding='SAME'),\n",
    "tfp.layers.Convolution2DFlipout(16, kernel_size=5, padding='SAME',\n",
    "                                kernel_divergence_fn=kl_divergence_function,\n",
    "                                bias_divergence_fn = kl_divergence_function,\n",
    "                                kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                                    loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                                    untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                                ),\n",
    "                                bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                                    is_singular=True,\n",
    "                                    loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                                    untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                                ),\n",
    "                                activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=[2, 2],padding='SAME'),\n",
    "tfp.layers.Convolution2DFlipout(120, kernel_size=5, padding='SAME',\n",
    "                                kernel_divergence_fn=kl_divergence_function,\n",
    "                                bias_divergence_fn = kl_divergence_function,\n",
    "                                kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                                    loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                                    untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                                ),\n",
    "                                bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                                    is_singular=True,\n",
    "                                    loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                                    untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                                ),\n",
    "                                activation='relu'),\n",
    "tf.keras.layers.Flatten(),\n",
    "tfp.layers.DenseFlipout(84, kernel_divergence_fn=kl_divergence_function,\n",
    "                        bias_divergence_fn = kl_divergence_function,\n",
    "                        kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                            loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                            untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                        ),\n",
    "                        bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                            is_singular=True,\n",
    "                            loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                            untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                        ),\n",
    "                        activation='relu'),\n",
    "tfp.layers.DenseFlipout(NUM_CLASSES, kernel_divergence_fn=kl_divergence_function,\n",
    "                        bias_divergence_fn = kl_divergence_function,\n",
    "                        kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                            loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                            untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                        ),\n",
    "                        bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(\n",
    "                            is_singular=True,\n",
    "                            loc_initializer=RandomNormal(stddev=0.1, seed=42),\n",
    "                            untransformed_scale_initializer=RandomNormal(mean=-3.0, stddev=0.1, seed=42)\n",
    "                        ),\n",
    "                        activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = model.losses[1]\n",
    "#sum(model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем нашу нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 1.2728 - accuracy: 0.8335\n",
      "Epoch 2/3\n",
      "378/469 [=======================>......] - ETA: 5s - loss: 0.8679 - accuracy: 0.9630"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_acc=model.evaluate(x_test,y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emnist_path = 'C:/Users/kamen/DIPLOM/'\n",
    "# #X-test - буквы для теста, Y-test - метки букв\n",
    "# X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-letters-test-images-idx3-ubyte')\n",
    "# Y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-letters-test-labels-idx1-ubyte')\n",
    "# X_test = X_test.reshape((20800,28,28,1))\n",
    "# X_test = X_test.astype('float32')/255\n",
    "# X_test=X_test[:10000,:,:,:]\n",
    "# Y_test=to_categorical(Y_test)\n",
    "# tf.shape(X_test)\n",
    "# X_test = np.rot90(X_test,1,axes=(-2,-3))\n",
    "# X_test=X_test[:,:,::-1,:]\n",
    "# validation_set=np.concatenate([X_test,x_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = model.predict(x_test[:,:,:,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = x_test[24,:,:,:].reshape((1,28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция сэмплирования N раз полученных массивов вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def Sampling(test_set):\n",
    "    print(' ... Running monte carlo inference')\n",
    "    probs = tf.stack([model.predict(test_set)\n",
    "        for _ in range(num_monte_carlo)],axis=0)\n",
    "    mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "    return mean_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Начало лишних в данный момент функций (определение порога распознавания - в данный момент лишние и закоменчены)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_probability=Sampling(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict_set_letters_label = np.zeros(len(validation_set))#Поиск порога отказа\n",
    "# Predict_set_letters_prob = np.zeros(len(validation_set))\n",
    "# for i in range(len(validation_set)):\n",
    "#     Predict_set_letters_label[i] = np.argmax(mean_probability[i,:])\n",
    "#     Predict_set_letters_prob[i]=np.max(mean_probability[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failure_threshold=tf.reduce_mean(Predict_set_letters_prob,axis=0)\n",
    "# failure_threshold=tf.reshape(failure_threshold,[]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(failure_threshold,\"Порог минимальной вероятности\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Predict_a_picture(picture_to_predict):\n",
    "#     array_probability = Sampling(picture_to_predict)\n",
    "#     probability = np.max(array_probability)\n",
    "#     label = np.argmax(array_probability)  \n",
    "#     if (probability<failure_threshold):\n",
    "#         print(\"This is not a digit\")\n",
    "#     else:\n",
    "#         print(\"Это цифра\",labels,\"с вероятностью\",probability)\n",
    "#     return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конец лишних функций - далее работаем с текущей задачей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция построения состязательной атаки для конкретной картинки при помощи FGSM метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "def create_adversarial_pattern(input_image):\n",
    "    predict_array = Sampling(input_image)\n",
    "    number_index =np.argmax(predict_array)\n",
    "    input_image=tf.convert_to_tensor(input_image)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model(input_image)\n",
    "        # эту строчку нужно сэмплировать\n",
    "        print((prediction))\n",
    "        label = tf.one_hot(number_index,predict_array.shape[-1])\n",
    "        label = tf.reshape(label, (1, predict_array.shape[-1]))\n",
    "        loss = loss_object(label, prediction)#+kl_divergence(...)\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    signed_grad = signed_grad.numpy()\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение гистограммы вероятностей + изображение под действием состязательной атаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adv_final(img):\n",
    "    indices= list(range(0,10))\n",
    "    attack = create_adversarial_pattern(img)\n",
    "    for i in range(25):\n",
    "        data_array = Sampling(np.clip(img+0.01*i*attack,a_max = 1.,a_min = 0.))[0]\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "        axes[0].bar(indices,data_array)\n",
    "        axes[0].set_title('Атака FGSM - методом, eps =%s '%(0.01*(i)))\n",
    "        axes[0].set_xlabel('Метка класса')\n",
    "        axes[0].set_ylabel('Вероятность')\n",
    "        axes[0].set_ylim(0,1.0)\n",
    "        image = np.clip(img[0,:,:,:]+0.01*i*attack[0,:,:,:],a_max = 1., a_min =0.)\n",
    "        image = tf.clip_by_value(image, -1, 1)\n",
    "        axes[1].imshow(image,cmap='gray')\n",
    "        plt.show()\n",
    "        print(np.max(data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_pic = x_test[159,:,:,:]\n",
    "test_pic = test_pic.reshape((1,28,28,1))\n",
    "build_adv_final(test_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(25):\n",
    "#     attacked_picture,data_array=adversarial_attack_impact(img,5,(i+1)*0.01)\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "#     axes[0].bar(indices,data_array[0])\n",
    "#     axes[0].set_title('Атака FGSM - методом, eps =%s '%(0.01*(i+1)))\n",
    "#     axes[0].set_xlabel('Метка класса')\n",
    "#     axes[0].set_ylabel('Вероятность')\n",
    "#     axes[0].set_ylim(0,1.0)\n",
    "#     axes[1].imshow(attacked_picture[0,:,:,0])\n",
    "#     plt.show()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
